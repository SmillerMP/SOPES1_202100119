
# Manual Tecnico Proyecto 2

![Grafana](./img/grafana-sopes1-p2.png)

El proyecto tiene como objetivo la utilizacion de kubernetes y el despliegue en la nube, el proyecto consiste en un sistema de "tweets" con el cual se busca generar una gran carga de trafico a travez de peticiones y endpoits, este sistema genera una gran carga en el sistema ya que necesita procesar multiples peticiones, y procesarlas y pasarlas a otros sistemas hasta llegar messages brokers para luego insertarlos en bases de datos no SQL y por ultimo visualizar los datos en tiempo real en Grafana

existen varios servicios que se utilizan en el proyecto que se especificaran mas a detalle:



## ğŸ” ComunicaciÃ³n entre aplicaciones

### ğŸŒ API REST
- Estilo de arquitectura para comunicaciÃ³n HTTP.
- Usa JSON para intercambiar datos.
- Es **sÃ­ncrona**: espera una respuesta inmediata.
- Ejemplo: `POST /weather`

### ğŸ”— gRPC (cliente y servidor)
- Sistema de comunicaciÃ³n moderno, rÃ¡pido y eficiente.
- Usa **Protobuf** (binario) en lugar de JSON.
- Se define con archivos `.proto`.
- **Cliente gRPC**: llama funciones remotas.
- **Servidor gRPC**: expone funciones a otros servicios.
- Puede ser **sÃ­ncrono o asÃ­ncrono**.

---

## ğŸ“© Sistemas de mensajerÃ­a

### ğŸ‡ RabbitMQ
- **Message broker** basado en colas.
- Usa el protocolo AMQP.
- ComunicaciÃ³n **asÃ­ncrona**.
- Ideal para tareas en segundo plano (emails, procesamiento, etc.).

### âš¡ Apache Kafka (Strimzi Kafka en Kubernetes)
- Plataforma de **streaming distribuido**.
- Usa **topics** en lugar de colas.
- Guarda mensajes por tiempo definido.
- Excelente para **Big Data**, **logs**, y **event-driven systems**.

### ğŸ§¾ Consumers
- Programas que **leen mensajes** de RabbitMQ o Kafka.
- Procesan la informaciÃ³n segÃºn el flujo de negocio.
- Se combinan para procesar de otra manera la informacion

---

## ğŸ§  Pruebas de carga y monitoreo

### ğŸ› Locust
- Herramienta para **pruebas de carga**.
- Simula muchos usuarios que hacen peticiones.
- Ãštil para pruebas de rendimiento y stress testing.

### ğŸ“Š Grafana
- Plataforma para **visualizaciÃ³n y monitoreo**.
- Muestra paneles con mÃ©tricas en tiempo real.
- Se conecta a fuentes como Prometheus, Redis, etc.

---

## ğŸ§± Registro y almacenamiento

### ğŸ›³ï¸ Harbor
- **Registro privado de imÃ¡genes Docker**.
- Permite subir, escanear y controlar imÃ¡genes.
- Alternativa a Docker Hub, ideal para entornos empresariales y Kubernetes.

### ğŸ§  Redis y Valkey
- Bases de datos **clave-valor en memoria**.
- AltÃ­simo rendimiento.
- Usos comunes:
  - Cache
  - Contadores rÃ¡pidos
  - Almacenamiento de sesiones
- **Valkey** es un **fork libre de Redis** mantenido por la comunidad.

</br>

## ğŸ³ Docker y â˜¸ï¸ Kubernetes

### Â¿QuÃ© es Docker?

**Docker** es una plataforma que permite crear, desplegar y ejecutar aplicaciones dentro de contenedores. Un contenedor es una unidad ligera y portÃ¡til que incluye todo lo necesario para que una aplicaciÃ³n se ejecute: cÃ³digo, runtime, librerÃ­as y configuraciones del sistema.

### ğŸ”¹ CaracterÃ­sticas de Docker

- **Aislamiento:** Cada contenedor corre de forma independiente.
- **Portabilidad:** Funciona igual en desarrollo, pruebas y producciÃ³n.
- **Eficiencia:** Es mÃ¡s liviano que una mÃ¡quina virtual.
- **Rapidez:** Inicia en segundos.
- **Reproducibilidad:** FÃ¡cil de replicar entornos exactos.

### ğŸ”§ Componentes principales de Docker

- **Docker Engine:** Servicio que permite construir y correr contenedores.
- **Dockerfile:** Archivo con instrucciones para construir una imagen.
- **Imagen Docker:** Plantilla para crear contenedores.
- **Contenedor:** Instancia de una imagen en ejecuciÃ³n.
- **Docker Hub:** Repositorio pÃºblico de imÃ¡genes Docker.

---

## Â¿QuÃ© es Kubernetes?

**Kubernetes** (abreviado K8s) es una plataforma de orquestaciÃ³n de contenedores. Automatiza el despliegue, escalado y administraciÃ³n de aplicaciones en contenedores.

### ğŸ”¹ CaracterÃ­sticas de Kubernetes

- **Escalado automÃ¡tico:** AÃ±ade o elimina contenedores segÃºn la carga.
- **RecuperaciÃ³n automÃ¡tica:** Reemplaza contenedores que fallan.
- **Balanceo de carga:** Distribuye el trÃ¡fico entre contenedores.
- **Despliegue continuo:** Facilita actualizaciones sin afectar la disponibilidad.
- **GestiÃ³n declarativa:** Define el estado deseado de tu sistema.

### ğŸ”§ Componentes principales de Kubernetes

- **Cluster:** Conjunto de nodos (mÃ¡quinas) que ejecutan contenedores.
- **Nodo:** MÃ¡quina (fÃ­sica o virtual) que corre aplicaciones.
- **Pod:** Unidad mÃ­nima de Kubernetes, puede contener uno o mÃ¡s contenedores.
- **Deployment:** Controla cÃ³mo se despliegan los pods.
- **Service:** Expone los pods como un servicio accesible en red.
- **Ingress:** Gestiona el acceso externo a los servicios (por HTTP/HTTPS).

---

## ğŸš€ Â¿CÃ³mo se complementan Docker y Kubernetes?

- Docker se encarga de **empaquetar** aplicaciones.
- Kubernetes se encarga de **administrar** esas aplicaciones empaquetadas a gran escala.

Usarlos juntos permite desplegar apps de manera mÃ¡s rÃ¡pida, eficiente y con alta disponibilidad.

</br>

## Funcionamiento del sistema

1. El sistema descarga las imagenes de Docker del registry Harbor
2. Locust hace las peticiones al ingres, que distribuye la carga al servicio de rust, que contiene una API
3. Pasa a una segunda API en Go, y a su vez a un gRPC Client
4. El gRPC Client manda las peticiones a 2 gRPC Server, uno para Kafka y otro para RabbitMQ
5. Los gRPC Server se encargan de metar cada uno de los mensajes recividos a las colas.
6. Los consumers extraen y procesan la informaciÃ³m para luego meterla en Redis y Valkey
7. Grafana extrae estos datos de las bases de datos y las muestra en graficos en tiempo real


</br>

# ğŸ“˜ Preguntas

## ğŸŒ€ Â¿CÃ³mo funciona Kafka?

**Apache Kafka** es una plataforma distribuida para el procesamiento de flujos de datos en tiempo real. EstÃ¡ diseÃ±ada para ser altamente escalable, tolerante a fallos y extremadamente rÃ¡pida.

### ğŸ”§ Arquitectura bÃ¡sica de Kafka

- **Productores (Producers):** Aplicaciones que envÃ­an datos a Kafka.
- **Temas (Topics):** CategorÃ­as o canales donde se almacenan los mensajes.
- **Particiones:** Cada tema se divide en particiones para distribuir la carga.
- **Consumidores (Consumers):** Aplicaciones que leen datos desde Kafka.
- **Broker:** Servidor Kafka que almacena los datos y gestiona las solicitudes.
- **Zookeeper:** Sistema auxiliar que gestiona la configuraciÃ³n y el consenso del clÃºster (aunque ya se estÃ¡ migrando a KRaft para eliminar Zookeeper).

### ğŸ§­ Â¿CÃ³mo fluye la informaciÃ³n?

1. Un **productor** publica un mensaje en un **tema**.
2. El mensaje se almacena en una **particiÃ³n** del tema.
3. Uno o varios **consumidores** se suscriben al tema y leen los mensajes en orden.

Kafka es ideal para sistemas **event-driven**, **microservicios**, y procesamiento de datos en **streaming**.

</br>

## ğŸ” Â¿CÃ³mo difiere Valkey de Redis?

**Valkey** es un fork comunitario de Redis, creado despuÃ©s de que Redis Labs cambiÃ³ la licencia del proyecto original (Redis pasÃ³ de BSD a una licencia no completamente libre).

### ğŸ§© Diferencias clave entre Valkey y Redis:

| CaracterÃ­stica     | Redis                          | Valkey                        |
|--------------------|--------------------------------|-------------------------------|
| Licencia           | Redis Source Available (RSAL)  | BSD 3-Clause (100% open)     |
| Comunidad          | Controlado por Redis Ltd.      | Proyecto abierto, gobernado por la comunidad |
| Compatibilidad     | Altamente compatible           | Totalmente compatible         |
| Futuro             | Enfocado en productos comerciales | Enfocado en la libertad y comunidad |
| CÃ³digo base        | Original de Redis              | Fork de Redis 7.2.4 (marzo 2024) |

Valkey busca mantenerse libre, abierta y comunitaria, similar a cÃ³mo ocurriÃ³ con **MariaDB** despuÃ©s del cambio en **MySQL**.

</br>

## ğŸŒ Â¿Es mejor gRPC que HTTP?

**Depende del caso de uso**, pero aquÃ­ te doy una comparaciÃ³n clara entre **gRPC** y **HTTP REST tradicional**.

### ğŸ” ComparaciÃ³n general:

| CaracterÃ­stica       | gRPC                            | HTTP/REST                    |
|----------------------|----------------------------------|------------------------------|
| Protocolo            | HTTP/2 + Protobuf               | HTTP/1.1 + JSON              |
| Rendimiento          | MÃ¡s rÃ¡pido (binario)            | MÃ¡s lento (texto)            |
| Tolerancia a errores | Estricta                        | MÃ¡s flexible                 |
| Streaming            | Soportado (bidireccional)       | Limitado (solo long polling) |
| DefiniciÃ³n de API    | `.proto` (esquemas estrictos)   | OpenAPI/Swagger (opcional)  |
| Lenguajes            | Multi-lenguaje (autogenerado)   | Multi-lenguaje (manual)      |
| Legibilidad          | Baja (binario)                  | Alta (JSON legible)          |
| AdopciÃ³n             | Alta en microservicios internos | Alta en APIs pÃºblicas        |

### âœ… Â¿CuÃ¡ndo usar gRPC?

- ComunicaciÃ³n entre microservicios.
- Alta eficiencia y bajo consumo de red.
- Necesidad de streaming de datos en tiempo real.

### âœ… Â¿CuÃ¡ndo usar HTTP REST?

- APIs pÃºblicas o integraciones con terceros.
- Mayor interoperabilidad con clientes que usan navegador.
- Cuando se prefiere legibilidad y simplicidad.

</br>

## ğŸš€ Â¿Hubo mejora al utilizar dos rÃ©plicas en los Deployments de API REST y gRPC?

### ğŸ§ª Respuesta corta

**No hubo una mejora tan crÃ­tica como se esperaba.** Aunque se observaron pequeÃ±os beneficios en concurrencia y manejo de carga, la mayor ganancia vino del uso de **gRPC**, que es considerablemente mÃ¡s rÃ¡pido que HTTP REST en tÃ©rminos de rendimiento y eficiencia.


### âš™ï¸ JustificaciÃ³n tÃ©cnica

#### ğŸ” RÃ©plicas en los Deployments

Usar dos rÃ©plicas en los Deployments (tanto para la API como para los servidores gRPC) ayuda a distribuir la carga y mejorar la tolerancia a fallos, pero:

- En este caso **la carga principal estÃ¡ en los servidores gRPC**, donde se hace procesamiento en paralelo con `goroutines`.
- La API en Fiber es muy liviana y rÃ¡pida, por lo que **no se convierte en un cuello de botella**, incluso con una sola rÃ©plica.
- Las rÃ©plicas fueron Ãºtiles en pruebas de carga, pero **no escalaron tanto el rendimiento como se esperaba**, ya que los recursos del clÃºster y el procesamiento interno (por ejemplo, I/O o redes) seguÃ­an siendo los lÃ­mites reales.

### âš¡ Ventajas de gRPC frente a HTTP REST en tu caso

El mayor impacto positivo vino del uso de **gRPC**, por varias razones:

#### 1. ğŸ”„ ComunicaciÃ³n binaria eficiente

- gRPC usa **Protocol Buffers (Protobuf)**, que es mucho mÃ¡s ligero que JSON.
- La serializaciÃ³n/deserializaciÃ³n es mÃ¡s rÃ¡pida y ocupa menos espacio.

#### 2. ğŸš€ TransmisiÃ³n por HTTP/2

- Soporta **multiplexaciÃ³n**, es decir, mÃºltiples mensajes en una sola conexiÃ³n TCP.
- Reduce la latencia y mejora el rendimiento en llamadas paralelas.

#### 3. ğŸ§µ Paralelismo en el cliente

Tu API estÃ¡ enviando chunks de datos en paralelo (10 goroutines por servidor), lo que:

- **Satura bien el ancho de banda disponible.**
- Permite que los dos servidores gRPC (Kafka y RabbitMQ) reciban datos al mismo tiempo.
- gRPC lo maneja mucho mejor que una REST API que procesarÃ­a cada chunk secuencialmente.


### ğŸ“Š ConclusiÃ³n

Si bien aÃ±adir rÃ©plicas aporta algo de mejora en resiliencia y concurrencia, en este caso **no fue un cambio tan crÃ­tico** porque:

- El procesamiento ya era eficiente.
- El protocolo gRPC fue el verdadero impulsor de rendimiento.
- Tu estrategia de **paralelismo con goroutines y chunking** ya optimizaba bastante bien el flujo de datos.

Por tanto, **la mayor mejora proviene del protocolo (gRPC) y el diseÃ±o del cliente**, mÃ¡s que de la replicaciÃ³n en sÃ­.

</br>

## Â¿QuÃ© utilicÃ© para los consumidores y por quÃ©?

### RabbitMQ + Valkey

- **RabbitMQ** fue utilizado como sistema de colas de mensajes porque proporciona:
  - Fiabilidad en la entrega de mensajes (*message acknowledgment*).
  - Entrega ordenada.
  - Buen manejo de cargas moderadas de datos.
  - Ideal para arquitecturas *push-based*.

- **Valkey** (fork de Redis) fue elegido como sistema de almacenamiento temporal en memoria por:
  - Su velocidad para operaciones como `HINCRBY` e `INCR`.
  - Su compatibilidad con Redis y facilidad de integraciÃ³n en Go.
  - Uso eficiente de estructuras de datos como `hash` para contar ocurrencias por paÃ­s.

- **Goroutines** fueron utilizadas para procesar mÃºltiples mensajes en paralelo, configuradas dinÃ¡micamente con una variable de entorno (`NO_GOROUTINES`), lo cual permite escalar segÃºn los recursos disponibles.

---

### Kafka + Redis

- **Kafka** fue seleccionado como sistema de colas de alta disponibilidad y rendimiento porque:
  - Soporta altos volÃºmenes de mensajes (*pull-based*).
  - Es ideal para sistemas distribuidos y procesamiento en tiempo real.
  - Permite mantener el historial de mensajes, Ãºtil para depuraciÃ³n o reenvÃ­o.

- **Redis** fue utilizado como backend para el almacenamiento de contadores por:
  - Su rapidez en operaciones en memoria.
  - La madurez y estabilidad de su cliente oficial en Go.
  - Eficiencia para estructuras clave-valor y operaciones atÃ³micas.

- Al igual que en el caso anterior, se usaron **goroutines** y **canales** (`chan []byte`) para distribuir el trabajo entre varios workers, lo que mejora el rendimiento y el uso de CPU.
